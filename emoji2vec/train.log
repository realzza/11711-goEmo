--------------------------------------------------------------------------------
EMOJI TRAINING
--------------------------------------------------------------------------------
Hyperparameters:
k        768
pos_ex   4
ratio    1
mb       8
epochs   40
learning         0.001
dropout  0.0
dataset  unicode
reading training data from: data/training
loading embeddings...
Training: k=768, batch=4, epochs=40, ratio=1, dropout=0.0
Epoch: 1
 Training loss: 0.64
 Training acc: 0.61
 Training f1: 0.61
 ===================
Epoch: 2
 Training loss: 0.47
 Training acc: 0.78
 Training f1: 0.8
 ===================
Epoch: 3
 Training loss: 0.36
 Training acc: 0.85
 Training f1: 0.86
 ===================
Epoch: 4
 Training loss: 0.3
 Training acc: 0.88
 Training f1: 0.89
 ===================
Epoch: 5
 Training loss: 0.25
 Training acc: 0.91
 Training f1: 0.91
 ===================
Epoch: 6
 Training loss: 0.22
 Training acc: 0.93
 Training f1: 0.93
 ===================
Epoch: 7
 Training loss: 0.2
 Training acc: 0.93
 Training f1: 0.93
 ===================
Epoch: 8
 Training loss: 0.17
 Training acc: 0.94
 Training f1: 0.94
 ===================
Epoch: 9
 Training loss: 0.15
 Training acc: 0.95
 Training f1: 0.95
 ===================
Epoch: 10
 Training loss: 0.13
 Training acc: 0.96
 Training f1: 0.96
 ===================
Epoch: 11
 Training loss: 0.16
 Training acc: 0.95
 Training f1: 0.95
 ===================
Epoch: 12
 Training loss: 0.16
 Training acc: 0.96
 Training f1: 0.96
 ===================
Epoch: 13
 Training loss: 0.12
 Training acc: 0.96
 Training f1: 0.96
 ===================
Epoch: 14
 Training loss: 0.15
 Training acc: 0.96
 Training f1: 0.96
 ===================
Epoch: 15
 Training loss: 0.13
 Training acc: 0.96
 Training f1: 0.96
 ===================
Epoch: 16
 Training loss: 0.13
 Training acc: 0.96
 Training f1: 0.96
 ===================
Epoch: 17
 Training loss: 0.14
 Training acc: 0.97
 Training f1: 0.96
 ===================
Epoch: 18
 Training loss: 0.12
 Training acc: 0.97
 Training f1: 0.97
 ===================
Epoch: 19
 Training loss: 0.11
 Training acc: 0.97
 Training f1: 0.96
 ===================
Epoch: 20
 Training loss: 0.12
 Training acc: 0.97
 Training f1: 0.97
 ===================
Epoch: 21
 Training loss: 0.12
 Training acc: 0.97
 Training f1: 0.97
 ===================
Epoch: 22
 Training loss: 0.09
 Training acc: 0.97
 Training f1: 0.97
 ===================
Epoch: 23
 Training loss: 0.12
 Training acc: 0.97
 Training f1: 0.97
 ===================
Epoch: 24
 Training loss: 0.12
 Training acc: 0.97
 Training f1: 0.97
 ===================
Epoch: 25
 Training loss: 0.13
 Training acc: 0.97
 Training f1: 0.97
 ===================
Epoch: 26
 Training loss: 0.09
 Training acc: 0.97
 Training f1: 0.97
 ===================
Epoch: 27
 Training loss: 0.09
 Training acc: 0.98
 Training f1: 0.97
 ===================
Epoch: 28
 Training loss: 0.14
 Training acc: 0.97
 Training f1: 0.97
 ===================
Epoch: 29
 Training loss: 0.08
 Training acc: 0.98
 Training f1: 0.98
 ===================
Epoch: 30
 Training loss: 0.12
 Training acc: 0.98
 Training f1: 0.98
 ===================
Epoch: 31
 Training loss: 0.11
 Training acc: 0.98
 Training f1: 0.97
 ===================
Epoch: 32
 Training loss: 0.07
 Training acc: 0.98
 Training f1: 0.98
 ===================
Epoch: 33
 Training loss: 0.1
 Training acc: 0.98
 Training f1: 0.97
 ===================
Epoch: 34
 Training loss: 0.09
 Training acc: 0.98
 Training f1: 0.98
 ===================
Epoch: 35
 Training loss: 0.1
 Training acc: 0.97
 Training f1: 0.97
 ===================
Epoch: 36
 Training loss: 0.11
 Training acc: 0.97
 Training f1: 0.97
 ===================
Epoch: 37
 Training loss: 0.09
 Training acc: 0.98
 Training f1: 0.97
 ===================
Epoch: 38
 Training loss: 0.12
 Training acc: 0.98
 Training f1: 0.98
 ===================
Epoch: 39
 Training loss: 0.07
 Training acc: 0.98
 Training f1: 0.98
 ===================
Epoch: 40
 Training loss: 0.09
 Training acc: 0.97
 Training f1: 0.97
 ===================
train: Accuracy(>0.5): 0.9856836077308518, f1: 0.9927901946647442, auc: N/A
dev: Accuracy(>0.5): 0.778, f1: 0.7245657568238213, auc: 0.9259999999999999